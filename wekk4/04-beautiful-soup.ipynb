{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup\n",
    "- great 'screen scraping' package\n",
    "- tons of interesting data on webpages designed for people, not programs\n",
    "- makes it easy to extract information from complex web pages and XML documents\n",
    "- often can figure out what to do by playing interactively\n",
    "- [doc](http://www.crummy.com/software/BeautifulSoup/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "# Want to find all the headlines on the front page of the [New York Times](http://nyt.com)\n",
    "- look at webpage source - html structure is quite complex\n",
    "- would be very difficult using with string.find() or regular expressions\n",
    "- soup reads in the page of interest, then you can query it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'lxml' is a XML parser(parses HTML too)\n",
    "# must tell soup what unicode decoding to use\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "nf2 = urllib.request.urlopen('http://nyt.com')\n",
    "sp = BeautifulSoup(nf2, 'lxml', from_encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# headlines seem to be contained in 'h2' elements\n",
    "\n",
    "sp.findAll('h2')[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first 'h2' element\n",
    "\n",
    "h2 = sp.h2\n",
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# can pull 'a' element out of 'h2'\n",
    "# this 'a' element is a picture\n",
    "\n",
    "a=h2.find('a')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try pulling the 'a' out of all 'h2' elements\n",
    "# looks like we get mostly headlines\n",
    "\n",
    "al=[h2.find('a') for h2 in sp.findAll(\"h2\")]\n",
    "al[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pull out the 'a' link text \n",
    "\n",
    "[a.contents for a in al if a != None][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter out images\n",
    "\n",
    "[a.contents for a in al if a != None and len(a)==1][:30]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
